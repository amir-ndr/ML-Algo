{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regulation-produce",
   "metadata": {},
   "source": [
    "**regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-respondent",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_scorSe(y_predict,y_test)\n",
    "# explained variance\n",
    "regr.score(x,y)\n",
    "# ===============\n",
    "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y)))\n",
    "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\n",
    "#==============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-commons",
   "metadata": {},
   "source": [
    "#### Simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ruled-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x_train,y_train)\n",
    "regr.predict(x_test)\n",
    "# coeff and intercept\n",
    "regr.coef_\n",
    "regr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-flashing",
   "metadata": {},
   "source": [
    "#### polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "x = poly.fit_transform(X_train)\n",
    "regr.fit(X,y_train)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-rover",
   "metadata": {},
   "source": [
    "#### Non linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-intranet",
   "metadata": {},
   "source": [
    "we can use **curve_fit** which uses non-linear least squares to fit our sigmoid function(ex), to data. Optimal values for the parameters so that the sum of the squared residuals of sigmoid(xdata, *popt) - ydata is minimized.\n",
    "\n",
    "popt are our optimized parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "popt, pcov = curve_fit(sigmoid, xdata, ydata)\n",
    "#print the final parameters\n",
    "print(\" beta_1 = %f, beta_2 = %f\" % (popt[0], popt[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-astronomy",
   "metadata": {},
   "source": [
    "**classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-buddy",
   "metadata": {},
   "source": [
    "#### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "# label Encoding\n",
    "from sklearn import preprocessing\n",
    "le_sex = preprocessing.LabelEncoder()\n",
    "le_sex.fit(['F','M'])\n",
    "X[:,1] = le_sex.transform(X[:,1]) \n",
    "#=========\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "feature_mtx = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-prague",
   "metadata": {},
   "source": [
    "#### metrrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))  # jaccard_score\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))\n",
    "#==========\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(y_test, yhat,pos_label=0)\n",
    "#=============\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "print (classification_report(y_test, yhat))\n",
    "#=================\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, yhat_prob)\n",
    "#=============\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, yhat, average='weighted') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-memphis",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 4\n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "neigh.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-technician",
   "metadata": {},
   "source": [
    "#### decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "drugTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "drugTree.fit(X_trainset,y_trainset)\n",
    "predTree = drugTree.predict(X_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-concern",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)  # ‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’ \n",
    "yhat = LR.predict(X_test)\n",
    "yhat_prob = LR.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-scoop",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train) \n",
    "yhat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-visit",
   "metadata": {},
   "source": [
    "**clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-smooth",
   "metadata": {},
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "k_means = KMeans(init = \"k-means++\", n_clusters = 4, n_init = 12)\n",
    "k_means.fit(X)\n",
    "k_means_labels = k_means.labels_\n",
    "k_means_cluster_centers = k_means.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-brunei",
   "metadata": {},
   "source": [
    "#### Hierarchical-agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy \n",
    "from scipy.spatial import distance_matrix \n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "\n",
    "agglom = AgglomerativeClustering(n_clusters = 4, linkage = 'average')\n",
    "agglom.fit(X1,y1)\n",
    "dist_matrix = distance_matrix(X1,X1) \n",
    "Z = hierarchy.linkage(dist_matrix, 'complete')\n",
    "dendro = hierarchy.dendrogram(Z)\n",
    "\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "max_d = 3\n",
    "clusters = fcluster(Z, max_d, criterion='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-notebook",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN \n",
    "epsilon = 0.3\n",
    "minimumSamples = 7\n",
    "db = DBSCAN(eps=epsilon, min_samples=minimumSamples).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
